# Lab8_12012505_占陈郅



### Purpose of this lab

> 1. Test and master the processing of median  smoothing on speech parameter estimation 
> 2. Test the commonly-used algorithms on pitch  estimation (i.e., autocorrelation method,  ceptrum method)



### Lab results and analysis

#### Problem 1

<img src="C:\Users\M__zzZ\AppData\Roaming\Typora\typora-user-images\image-20230413151649018.png" alt="image-20230413151649018" style="zoom:50%;" />

​	The focus is on calculating the different ways of smoothing speech signals.

Code:

```matlab
clc 
clear all 
close all 

[y, fs] = audioread("test_16k.wav"); 

frame_length = 10 * fs / 1e3; 
frame_shift = 5 * fs / 1e3; 


window = hamming(frame_length); 

frame_mat = enframe(y, window, frame_shift); 
frame_num = size(frame_mat, 1); 
[zcr] = deal(zeros(frame_num, frame_length));
for i = 1:frame_num
    zcr(i,:) = zerocrossing(frame_mat(i,:)) / frame_length; 
end


% Deframe_matn linear filter
Wp = [0.1 * fs] ./ (fs / 2); Ws = [0.2 * fs] ./ (fs / 2); Rp = 3; Rs = 40; 
[~, Wn] = buttord(Wp, Ws, Rp, Rs); 
[b, a] = fir1(41, Wn); 
freqz(b, a); 

zcr = reshape(zcr, [frame_num*frame_length, 1]);
zcr_linear = filter(b, a, zcr);
zcr_median_7 = median_smoother(zcr, 7); 
zcr_median_5 = median_smoother(zcr, 5); 
zcr_combi_7 = filter(b, a, zcr_median_7); 
zcr_combi_5 = filter(b, a, zcr_median_5); 
zcr_combi2_7 = median_smoother(zcr_linear, 7); 
zcr_combi2_5 = median_smoother(zcr_linear, 5);

figure; 
subplot(311), plot(zcr(1:0.5e3)), ylabel("zero" +newline+"crossing" +newline+"rate"), title("Fig.1.1"); 
subplot(312), plot(zcr_linear(1:0.5e3)), ylabel("linear"); 
subplot(313), hold on; 
plot(zcr_median_7(1:0.5e3)), plot(zcr_median_5(1:0.5e3)),  xlabel("Samples"), ylabel("median"); 
legend(["7, samples", "5, samples"], 'Location', 'southeast'); 
figure; 
subplot(311), hold on; 
plot(zcr_combi_7(1:0.5e3)), plot(zcr_combi_5(1:0.5e3)), ylabel("1st median"), title("Fig.1.2"); 
legend(["7, samples", "5, samples"], 'Location', 'southeast'); 
subplot(312), hold on; 
plot(zcr_combi2_7(1:0.5e3)), plot(zcr_combi2_5(1:0.5e3)), ylabel("1st linear"); 
legend(["7, samples", "5, samples"], 'Location', 'southeast'); 
subplot(313), hold on; 
plot(zcr_combi2_7(1:0.5e3) - zcr_combi_7(1:0.5e3)), plot(zcr_combi2_5(1:0.5e3) - zcr_combi_5(1:0.5e3)), xlabel("Samples"), ylabel("difference"); 
legend(["7, samples", "5, samples"], 'Location', 'southeast'); 
```

Result:

| zero-crossing rate, linear, median                        | combination                                               |
| --------------------------------------------------------- | --------------------------------------------------------- |
| ![11](C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB8\11.png) | ![12](C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB8\12.png) |

​	Four different smoothing methods are used here: median smoothing, zcr smoothing, linear and combination smoothing. Among them, low-pass filtering smoothing is achieved by designing a low-pass filter to preserve the low-frequency band and remove interference from the high-frequency band; Median smoothing is the process of removing noise by performing median filtering on the original zero crossing rate curve; Combination smoothing is a combination of low-pass filtering smoothing and median smoothing methods. These smoothing methods can be used for feature extraction and analysis of speech signals.



#### Problem 2

> Program an autocorrelation-based pitch detector using the modified autocorrelation function in MATLAB. Compare the results using both the original speech file and those obtained from a bandpass filtered version of the speech file. The steps to follow for implementing the pitch detector are the following:
>
> 1. specify whether the talker is a male or female (the program uses the talker gender to set ranges for the pitch period contour);
>
> 2. read in the speech file (including determining the speech sampling rate, fs);
>
> 3. convert the sampling rate to a standard value of fsout=10000 Hz for this exercise;
>
> 4. design and implement a bandpass filter to eliminate DC offset, 60 Hz hum, and high frequency (above 1000 Hz) signal, using the design parameters:
>
>    stopband from 0 to 80 Hz
>    transition band from 80 to 150 Hz
>    passband from 150to 900 Hz
>    transition band from 900 to 970 Hz
>    stopband from 970 to 5000 Hz
>    filter length of n=3 01 samples
>
> 5. save both the full band speech and the bandpass filtered speech files for processing and comparison;
> 6. play both the original and bandpass filtered speech files to be sure that the filtering worked properly;
> 7. block the signal into frames of length L=400 samples (corresponding to 40 msec in duration), with frame shift of R=100 samples (corresponding to 10 msec shift duration);
> 8. compute the frame-by-frame modified correlation between the frames of signal specified as:
>     s1[n] = [s[n],s[n + 1],...,s[n + L-1]],
>     s2[n]=[s[n],s[n +1],...,sn +L+pdhigh -1],
>     where n is the starting sample of the current frame, and pdhigh is the longest anticipated pitch period (based on the gender of the speaker) and is specified as:
>     pdhigh=fsout/150 for females and fsout/75for males
>     (Hint: Use the MATLAB function xcorr to compute the modified correlation between s1[n] and s2[n] as it is considerably faster than any other implementation)
> 9. search from pdlow to pdhigh to find the maximum of the modifed autocorrelationfunction (the putative pitch period estimate for the current frame), along with thevalue of the modified autocorrelation at the maximum (the confidence score), usingthe range estimate of
>     fsout/200 for malespdlow=fsout/300 for females.
>     do all operations on both the original file and the bandpass filtered speech file;
> 10. convert the confidence score (the value of the modified autocorrelation at the10maximum) to a log confidence, set a threshold at 0.75 of the maximum value of the log confidence score, and set the pitch period to zero for all frames whose log confidence scores fell below the threshold;
> 11. plot the resulting pitch period contour along with the log confidence scores for boththe original speech file and the bandpass filtered speech file: how do these contourscompare?
> 12. use a 5-point median smoother to smooth the pitch period scores as well as theconfidence scores;
> 13. plot the median smoothed pitch period scores along with the median smoothed confidence scores;
> 14. save the computed pitch period and confidence scores in the file out_autoc.mat.
>       Which processing works best; i.e, using the full band original speech file or using the bandpass filtered speech file? How much difference do you observe in the resulting pitch period contours?

To determine which processing works best, we can compare the resulting pitch period contours for the original speech file and the bandpass filtered speech file. We can observe the difference in the resulting pitch period contours by comparing the two plots.

Code:

```matlab
[s,fs] = audioread("s6.wav")
PitchDetector_Autocorrelation(s,fs,'male')
function [] = PitchDetector_Autocorrelation(s,fs,gender)
% 1. Specify whether the talker is a male or female (the program uses the talker gender to set ranges for the pitch period contour)
% Set gender to 'male' or 'female'
% 2. Read in the speech file (including determining the speech sampling rate, fs)
% 3. Convert the sampling rate to a standard value of fsout=10000 Hz for this exercise
fsout = 10000;
S = resample(S, fsout, fs);

% 4. Design and implement a bandpass filter to eliminate DC offset, 60 Hz hum, and high frequency (above 1000 Hz) signal, using the design parameters:
%    stopband from 0 to 80 Hz
%    transition band from 80 to 150 Hz
%    passband from 150 to 900 Hz
%    transition band from 900 to 970 Hz
%    stopband from 970 to 5000 Hz
%    filter length of n=301 samples
n = 301;
f = [0 80 150 900 970 5000]/(fsout/2);
a = [0 0 1 1 0 0];
b = firpm(n-1, f, a);
s_filtered = filter(b, 1, S);

% 5. Save both the full band speech and the bandpass filtered speech files for processing and comparison
audiowrite('speech_file_full.wav', S, fsout);
audiowrite('speech_file_filtered.wav', s_filtered, fsout);

% 6. Play both the original and bandpass filtered speech files to be sure that the filtering worked properly
sound(S, fsout);
pause(length(S)/fsout);
sound(s_filtered, fsout);

% 7. Block the signal into frames of length L=400 samples (corresponding to 40 msec in duration), with frame shift of R=100 samples (corresponding to 10 msec shift duration)
L = 400;
R = 100;
num_frames = floor((length(s_filtered)-L)/R) + 1;
frames = zeros(L, num_frames);
for i = 1:num_frames
    frames(:,i) = s_filtered((i-1)*R+1:(i-1)*R+L);
end

% 8. Compute the frame-by-frame modified correlation between the frames of signal specified as:
%    s1[n] = [s[n],s[n + 1],...,s[n + L-1]],
%    s2[n]=[s[n],s[n +1],...,sn +L+pdhigh -1],
%    where n is the starting sample of the current frame, and pdhigh is the longest anticipated pitch period (based on the gender of the speaker) and is specified as:
%    pdhigh=fsout/150 for females and fsout/75for males
%    (Hint: Use the MATLAB function xcorr to compute the modified correlation between s1[n] and s2[n] as it is considerably faster than any other implementation)
if strcmp(gender, 'male')
    pdhigh = fsout/75;
else
    pdhigh = fsout/150;
end
pitch_periods = zeros(1, num_frames);
for i = 1:num_frames
    s1 = frames(:,i);
    s2 = [s1(1:end-pdhigh); zeros(round(pdhigh),1)];
    r = xcorr(s1, s2);
    r = r(L:end);
    [~, locs] = findpeaks(r);
    if isempty(locs)
        pitch_periods(i) = NaN;
    else
        pitch_periods(i) = locs(1);
    end
end

% Plot pitch period contour
t = (0:num_frames-1)*R/fsout;
pitch_freqs = fsout./pitch_periods;
figure;
plot(t, pitch_freqs);
xlabel('Time (s)');
ylabel('Pitch frequency (Hz)');

%9
pdlow = round(fsout/300);
pitch_periods_max = zeros(1, num_frames);
confidence_scores = zeros(1, num_frames);
for i = 1:num_frames
    s1 = frames(:,i);
    s2 = [s1(1:end-pdhigh); zeros(round(pdhigh),1)];
    r = xcorr(s1, s2);
    r = r(L:end);
    [~, locs] = findpeaks(r(pdlow:pdhigh));
    if isempty(locs)
        pitch_periods_max(i) = NaN;
        confidence_scores(i) = NaN;
    else
        [~, max_loc] = max(r(locs+pdlow-1));
        pitch_periods_max(i) = locs(max_loc)+pdlow-1;
        confidence_scores(i) = r(pitch_periods_max(i));
    end
end

%10
log_confidence_scores = log(confidence_scores);
log_confidence_scores(isnan(log_confidence_scores)) = -Inf;
log_confidence_scores = log_confidence_scores - max(log_confidence_scores);
log_confidence_threshold = 0.75 * max(log_confidence_scores);
pitch_periods_max(log_confidence_scores < log_confidence_threshold) = 0;

%11
pitch_freqs_max = fsout./pitch_periods_max;
figure;
plot(t, pitch_freqs, t, pitch_freqs_max);
xlabel('Time (s)');
ylabel('Pitch frequency (Hz)');
legend('Original', 'Filtered');
figure;
plot(t, log_confidence_scores);
xlabel('Time (s)');
ylabel('Log confidence score');

%12
pitch_freqs_max_smoothed = medfilt1(pitch_freqs_max, 5);
log_confidence_scores_smoothed = medfilt1(log_confidence_scores, 5);

%13
figure;
plot(t, pitch_freqs_max_smoothed);
xlabel('Time (s)');
ylabel('Pitch frequency (Hz)');
figure;
plot(t, log_confidence_scores_smoothed);
xlabel('Time (s)');
ylabel('Log confidence score');

%14
save('out_autoc.mat', 'pitch_periods_max', 'log_confidence_scores_smoothed');
end
```

Using test_16k to test the function `PicthDetector_Autocorrelation("s6.wav",200,'male')`

| ![2](C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB8\2.png) | ![3](C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB8\3.png) |
| ------------------------------------------------------- | ------------------------------------------------------- |

| Use full band raw voice files                                | Using bandpass filtering for voice files                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| advantage:<br/>It can capture all frequency components of speech signals, including high-frequency and low-frequency components.<br/>Providing more information and details can help improve the accuracy of speech recognition and synthesis.<br/>Disadvantages:<br/>The original voice files are usually relatively large and require more storage space and processing power.<br/>The original voice file may contain some unnecessary noise and interference, which may affect the accuracy of speech recognition and synthesis. | advantage:<br/>It can remove unnecessary noise and interference, improve the accuracy of speech recognition and synthesis.<br/>Usually smaller than the original voice file, requiring less storage space and processing power.<br/>Disadvantages:<br/>Only speech signals within a certain frequency range can be captured, and some high-frequency or low-frequency components may be lost.<br/>It may affect the quality and naturalness of speech signals, thereby reducing the accuracy of speech recognition and synthesis. |

Therefore, if you need the highest quality voice signal, it is recommended to use full band raw voice files. If you need a smaller file size and better accuracy in speech recognition and synthesis, it is recommended to use bandpass filtered speech files.

*Note: Part of this task asked for help of Chat-GPT.*



#### Problem 3

​	In this section, we will use the cepstrum method for fundamental period estimation. The principle of using cepstrum to estimate the pitch period is similar to the autocorrelation method. A peak exists in the complex cepstrum of a voiced tone and appears at a time equal to the pitch period, while the complex cepstrum of a unvoiced tone does not show such a peak.

​	The main point of this method is to calculate the complex cepstrum and then deconvolve it, extract the sound gate excitation information, and look for the peak near the expected pitch period. If the peak exceeds the set threshold, it is a voiced tone, and the position of the peak is the pitch period. Otherwise, it is a unvoiced tone.

- Code1 - detect the pitch and point out

```matlab
gender = 'female';  % Or 'female' depending on the speaker
[s,fs] = audioread("s6.wav")
[pitch,pitch_period,peaks,med_pitch_period,med_confidence] = PitchDetector_Cepstrum(s, fs, gender);


function [pitch,pitch_period,peaks,med_pitch_period,med_confidence] = PitchDetector_Cepstrum(s, fs, gender)
N = length(s);
window = hamming(N);
s_windowed = s .* window;
s_cepstrum = real(ifft(log(abs(fft(s_windowed)))));
if strcmp(gender, 'male')
    min_pitch = 40;
    max_pitch = 167;
else
    min_pitch = 28;
    max_pitch = 67;
end

min_lag = round(fs / max_pitch);
max_lag = round(fs / min_pitch);
[~, pitch_lag] = max(s_cepstrum(min_lag:max_lag));
pitch_period = min_lag + pitch_lag - 1;
pitch = fs / pitch_period;

% Find all peaks in the cepstrum
peaks = findpeaks(s_cepstrum(min_lag:max_lag));

% Remove duplicate peak values
peaks = unique(peaks);

% Convert peak values to lag values
peak_lags = min_lag + find(ismember(s_cepstrum(min_lag:max_lag), peaks)) - 1;

% Convert lag values to pitch periods
peak_periods = peak_lags - 1;

% Convert pitch periods to times
peak_times = peak_periods / fs;

% Calculate median smoothed pitch period and confidence
med_pitch_period = medfilt1(peak_periods, 5);
med_confidence = medfilt1(peaks, 5);

% Plot the speech signal
t = (0:length(s)-1) / fs;
idx = find(t >= 0.015 & t <= 0.038);
figure;
plot(t(idx), s(idx));
xlabel('Time (s)');
ylabel('Amplitude');
title('Speech Signal with Detected Pitch and Resonance Peaks');

hold on;

% Plot the resonance peaks as points
plot(peak_times, s(peak_periods+1), 'r.');
hold off;

% Plot the median smoothed pitch period as a line
figure;
subplot(2,1,1);
med_pitch_time = t(med_pitch_period);
plot(med_pitch_time, s(med_pitch_period+1), 'g-', 'LineWidth', 2);
ylabel('Pitch Period');
title('Median Smoothed(5-Point Median)');
legend('Speech Signal', sprintf('Pitch (%.1f Hz)', pitch), 'Resonance Peaks', 'Median Smoothed Pitch Period');


% Plot the confidence as a line
subplot(2,1,2);
plot(peak_times, peaks, 'r.');
hold on;
plot(med_pitch_time, med_confidence, 'g-', 'LineWidth', 2);
xlabel('Time (s)');
ylabel('Confidence');
title('Pitch Confidence');

legend('Resonance Peaks', 'Median Smoothed Confidence');
hold off;
end
```

- Code2 - pitch period and confidence

```matlab
clc 
clear all 
close all 

 % 2.Audio read
[y, fs] = audioread("s6.wav"); 
 % 3.Resample
[P, Q] = rat(10e3/fs); 
y = resample(y, P, Q); fs = 10e3; 

 % 4.Deframe_matn linear filter
Wp = [100, 300] / (fs / 2); Ws = [50, 350] / (fs / 2); Rp = 3; Rs = 40; 
[~, Wn] = buttord(Wp, Ws, Rp, Rs); 
[b, a] = fir1(301, Wn); 
% freqz(b, a); 
 % 5.Linear filtering
y1 = filter(b, a, y); 
 % 6.
 % sound(y1)

 % 7.Framing
frame_length = 40 * fs / 1e3; 
frame_shift = 10 * fs / 1e3; 
window = hamming(frame_length); 
frame_mat = enframe(y1, window, frame_shift); 
frame_num = size(frame_mat, 1); 

 % 8.cepstrum
nfft = 4e3; 
[frame_fft, frame_mag, frame_phase, frame_log] = deal(zeros(frame_num, nfft)); 
[frame_ceps] = deal(zeros(frame_num, nfft)); 
for i = 1:1:frame_num 
    s1 = frame_mat(i, :); 
    frame_fft(i, :) = fft(s1, nfft); 
    frame_mag(i, :) = abs(frame_fft(i, :)); 
    frame_phase(i, :) = unwrap(angle(frame_fft(i, :))); 
    frame_log(i, :) = log(frame_mag(i, :)); 
%     frame_ceps(i,:) = real(ifft(frame_log(i,:) + 1i.*frame_phase(i,:), nfft));
    frame_ceps(i, :) = real(ifft(frame_fft(i, :), nfft)); 
end 
frame_ceps(isnan(frame_ceps)) = 0; 

 % 9.
frame_ceps1 = reshape(frame_ceps, [size(frame_ceps, 1) * size(frame_ceps, 2), 1]); 
% figure();
% index_start = 101; index_num = 20; index_end = index_start + index_num - 1;
% strips(frame_ceps1(frame_length*index_start:frame_length*index_end), frame_length);

 % 10.
nlow = 40; nhigh = 167; cut_rat = 0.9; interval = 13; median_p = 5; 

frame_ceps2 = transpose(frame_ceps); 
[p1_x, p1_y, p2_x, p2_y] = deal(zeros(frame_num,1));
[~, p1_x(:)] = max(frame_ceps2(:,:)); 
for i = 1:frame_num
    p1_y(i) = frame_ceps2(p1_x(i),i);
end

for i = 1:frame_num 
    x = p1_x(i); 
    if x <= round(interval/2) 
        frame_ceps2(1:x+round(interval/2), i) = 0; 
    elseif x > size(frame_ceps2, 1) - round(interval/2) 
        frame_ceps2(x-round(interval/2):end, i) = 0; 
    else 
        frame_ceps2(x-round(interval/2):x+round(interval/2), i) = 0; 
    end 
end 

[~, p2_x(:, 1)] = max(frame_ceps2(:, :)); 
for i = 1:frame_num
    p2_y(i) = frame_ceps2(p2_x(i),i);
end

pitch_period_tmp = abs(p1_x - p2_x); 
confidence_tmp = p1_y ./ p2_y; 
confidence_tmp(isnan(confidence_tmp)) = 0; 
confidence_tmp = confidence_tmp ./ max(confidence_tmp); 

index_low = find(pitch_period_tmp <= nlow); 
index_high = find(pitch_period_tmp >= nhigh); 
index_rat = find(confidence_tmp > cut_rat); 
index_del = unique([index_low; index_high; index_rat]); 
index_del = reshape(index_del, [length(index_del), 1]); 

pitch_period_tmp(index_del) = 0; 
confidence_tmp(index_del) = 0; 

pitch_period = median_smoother(pitch_period_tmp, median_p); 
confidence = median_smoother(confidence_tmp, median_p); 

figure; 
subplot(211); 
plot(1:frame_num, pitch_period); 
xlabel("Frame Number"), ylabel("Pitch Period"); 
title("File:s6, Median Smoothed" +newline+"(" +median_p + " -Point Median)"); 
subplot(212); 
plot(1:frame_num, confidence); 
xlabel("Frame Number"), ylabel("Confidence"); 
```

- Results

| detect the pitch and point out                          | pitch period and confidence                             |
| ------------------------------------------------------- | ------------------------------------------------------- |
| ![4](C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB8\4.png) | ![6](C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB8\6.png) |



- Analysis

The given code is a pitch detector that takes in an audio signal and returns the pitch, pitch period, peaks, median smoothed pitch period, and median confidence. The code uses the cepstrum method to detect the pitch of the audio signal. The cepstrum is the inverse Fourier transform of the logarithm of the magnitude of the Fourier transform of the windowed signal.

The code first applies a Hamming window to the audio signal and then calculates the cepstrum of the windowed signal. The cepstrum is then searched for the pitch period by finding the maximum value within a range of lag values that correspond to the minimum and maximum pitch values based on the gender of the speaker. The pitch period is then used to calculate the pitch frequency.

The code then finds all peaks in the cepstrum and removes duplicate peak values. The peak values are then converted to lag values and then to pitch periods and times. The median smoothed pitch period and confidence are then calculated using a 5-point median filter.

Finally, the code plots the speech signal with the detected pitch and resonance peaks, as well as the median smoothed pitch period and confidence.

Overall, this code provides a useful tool for analyzing the pitch of an audio signal and could be used in a variety of applications such as speech recognition and music analysis.
