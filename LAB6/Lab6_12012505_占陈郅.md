# Lab6_12012505_占陈郅

### Introduction

> The purposes of this lab
>
> 1. Learn to compute complex and real cepstra.
>
> 2. Compare the cepstra of voiced and unvoiced  segments.



### Lab results and analysis

#### Problem 1

- Write the function Cepstrum() to generate complex and real cepstrum.
- Use unwrap() to get the unwrapped angle of the result of fft.

```matlab
function [ccepstrum,rcepstrum] = Cepstrum(x,nfft)

    %Compute the complex cepstrum
    ccepstrum = ifft(log(abs(fft(x,nfft))) + 1i*unwrap(angle(fft(x,nfft))));
%     ccepstrum = cceps(x);
    %Compute the real cepstrum
    rcepstrum = real(ifft(log(abs(fft(x,nfft)))));
%     [rcepstrum,phase]=rceps(x);
    % Plot the input signal and the two outputs on the same page
    figure;
    subplot(3,1,1);
    plot(x);
    title('Input Signal');
    subplot(3,1,2);
    plot(abs(ccepstrum));
    title('Complex Cepstrum');
    subplot(3,1,3);
    plot(rcepstrum);
    title('Real Cepstrum');
end
```

Compare the two methods of computing Cepstrum
$$
x_1[n] = \delta[n]+0.85\delta[n-100]
$$

| Use fft, ifft and log(nfft = 1000)                      | Use cceps() and rceps()                                 |
| ------------------------------------------------------- | ------------------------------------------------------- |
| ![1](C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB6\1.png) | ![2](C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB6\2.png) |

Using cceps() and rceps() produce a quite different results compared to fft, after several tests, I found that if remove `1i*unwrap(angle(fft(x,nfft))));` in the fft method, then the results are the same. So it can be concluded that cceps() and rceps() do not take the unwrapped phase into consideration.



#### Problem 2

$$
x_2[n] = a^n u[n],|a|<1
$$

| a = 0.5, nfft = 10                                      | a = 0.9, nfft = 10                                      |
| ------------------------------------------------------- | ------------------------------------------------------- |
| ![3](C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB6\3.png) | ![4](C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB6\4.png) |
| **a = 0.5, nfft = 256**                                 | **a = 0.9, nfft = 256**                                 |
| ![5](C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB6\5.png) | ![6](C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB6\6.png) |

Since the signal is aperiodic, its cepstrum does not show any periodic component. As  told in class, the cepstrum decays along with quefrency.

In fact, because the process of calculating cepstrum requires fft and ifft operations, if the time signal has more high-frequency components, the relative spectrum can also have high-frequency components. Therefore, when performing ifft, a higher sampling frequency is required to avoid aliasing in the frequency domain



#### Problem 3

```matlab
function [  ] = speAnal( file_name, start, nsamples )
signal = audioread(file_name);
signal = signal(start:start+nsamples-1);
signal = signal.*hamming(nsamples);% use hamming window 

spectrum = 20*log(abs(fft(signal)));
[ccepstrum,cepstrum] = Cepstrum(signal,2048);
% do liftering by a 25% low-pass lifter, then turn back to log spectrum,
% then times 10 to dB scale
spectrum_liftered = real(20*(fft(cepstrum(1024:1024+100),2048)));

[spectrum,x1] = fftshift(spectrum);
figure()
subplot(2,2,1);plot(signal);title('windowed signal');ylim([-1,1]);
subplot(2,2,2);stem(x1, spectrum,'Marker','none');title('spectrum (dB)');xlim([-pi/2,pi/2]);
subplot(2,2,3);stem(cepstrum,'Marker','none');title('real cepstrum');axis([0,2048,-1,1]);
[spectrum_liftered,x2] = fftshift(spectrum_liftered);
subplot(2,2,4);stem(x2,spectrum_liftered,'Marker','none');title('low pass liftered spectrum (dB)');xlim([-pi/2,pi/2]);
end

function [outSpec, outx] = fftshift(inSpec)
% shift the fft result and generate the modified x value
inSpec = inSpec';
L = length(inSpec);
outSpec = [inSpec(round(L/2):L), inSpec(1:round(L/2))];
outx = (-L/2:L/2)*pi/L;
end
```

**A section of voiced speech**

<img src="C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB6\7.png" alt="7" style="zoom:75%;" />

For voiced sound, we can see that it contains more low-frequency components, and we can clearly see f1, f2, and f3. In addition, f0 can be considered a "sample" of the spectrum.

We cut the cepstrum and convert it back to the frequency domain. As the excitation has been removed, the enhanced spectrum becomes smoother. The lifting spectrum is now the convolution of glottic pulses, vocal channels, and radiation loads.

**A section of unvoiced speech**

<img src="C:\Users\M__zzZ\Documents\MATLAB\EE328\LAB6\8.png" alt="8" style="zoom:75%;" />

The unvoiced speech contains more high-frequency components. After liftering, the  spectrum also becomes smoother. Another significant effect is that the high frequency  components are reversed, which is the same with the voiced speech. 



### Summary

- Cepstrum analysis is divided into four steps. The first step is signal windowing. When generating sound signals, they are naturally limited by the physical morphology of the vocal region and are slow changing signals. Spectrum analysis does not require a long range, so windows are added.
- The second step after windowing is to perform spectrum analysis and convert to the frequency domain.
- The third step is to logarithmize the spectrum. From the second step, we know that slowly varying signals and rapidly varying signals are coupled in a product manner, so after taking the logarithm, slowly varying signals and rapidly varying signals are coupled in an additive manner.
- The fourth step is to take the Fourier transform (inverse transform, discrete Fourier transform and inverse transform only differ by one coefficient). In this way, the coupling between the high-frequency signal and the low-frequency signal after the product variable addition can be analyzed separately.
